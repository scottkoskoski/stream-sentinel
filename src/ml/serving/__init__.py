"""
High-Performance Model Serving Architecture

Production-grade C++ inference engine with ONNX Runtime for ultra-low-latency
fraud detection. Implements Martin Kleppmann distributed systems principles
with comprehensive fault tolerance and observability.

Key Components:
- ModelExporter: XGBoost to ONNX conversion with validation
- InferenceEngine: C++ ONNX Runtime with <2ms P99 latency
- PythonBindings: Zero-copy interfaces with graceful fallback
- ValidationFramework: Comprehensive accuracy and performance testing

Architecture Goals:
- 8-12x latency reduction (12ms â†’ 1.3ms)
- 10x throughput increase (10k+ predictions/second)
- 99.99% availability with automatic fallback
- <1e-6 prediction accuracy vs Python baseline
"""

from .model_export import ModelExporter, ExportConfig, ValidationResult
from .model_validation import ModelAccuracyValidator, PerformanceValidator
from .benchmarking import PerformanceBenchmark, BenchmarkResult

__version__ = "1.0.0"
__author__ = "Stream-Sentinel High-Performance Team"

__all__ = [
    # Model Export
    "ModelExporter",
    "ExportConfig", 
    "ValidationResult",
    
    # Validation Framework
    "ModelAccuracyValidator",
    "PerformanceValidator",
    
    # Performance Benchmarking
    "PerformanceBenchmark",
    "BenchmarkResult"
]